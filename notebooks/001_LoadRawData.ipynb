{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV DATA BASE LOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING NECESSARY LIBRARIES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the code performs the import of the libraries needed to load, manipulate and store data in a relational database. In addition, the working environment is adjusted to allow the import of modules from higher levels of the directory.\n",
    "The function sys.path.append(os.path.abspath(os.path.join(os.getcwd(), “..”))) adds the parent directory to the sys.path, facilitating the import of modules from higher paths within the project. connect_db (from src.database.db_connection): Provides functions to establish the connection with the database database.\n",
    "create_database (from src.database.database_create): Contains the functions for the creation and structuring of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import pandas as pd\n",
    "from src.database.db_conection import connect_db\n",
    "from src.database.database_create import create_database\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the csv to start data manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code fragment is a fundamental step in any data analysis process, as it allows the initial loading and verification of the data. The correct specification of the delimiter and encoding is key to avoid reading errors and ensure the integrity of the imported information. The visualization of the first records facilitates the understanding of the dataset and allows the identification of possible inconsistencies or preprocessing needs before further analysis. The pd.read_csv() function is used to read a CSV file located in the path ../data/candidates.csv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   First Name   Last Name                      Email Application Date  \\\n",
      "0  Bernadette   Langworth        leonard91@yahoo.com       2021-02-26   \n",
      "1      Camryn    Reynolds        zelda56@hotmail.com       2021-09-09   \n",
      "2       Larue      Spinka   okey_schultz41@gmail.com       2020-04-14   \n",
      "3        Arch      Spinka     elvera_kulas@yahoo.com       2020-10-01   \n",
      "4       Larue  Altenwerth  minnie.gislason@gmail.com       2020-05-20   \n",
      "\n",
      "   Country  YOE  Seniority                         Technology  \\\n",
      "0   Norway    2     Intern                      Data Engineer   \n",
      "1   Panama   10     Intern                      Data Engineer   \n",
      "2  Belarus    4  Mid-Level                     Client Success   \n",
      "3  Eritrea   25    Trainee                          QA Manual   \n",
      "4  Myanmar   13  Mid-Level  Social Media Community Management   \n",
      "\n",
      "   Code Challenge Score  Technical Interview Score  \n",
      "0                     3                          3  \n",
      "1                     2                         10  \n",
      "2                    10                          9  \n",
      "3                     7                          1  \n",
      "4                     9                          7  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/candidates.csv', sep=\";\", encoding='utf-8')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code fragment uses the .count() method of the pandas library to obtain the number of non-null values for each column in a previously loaded DataFrame. This method is useful to evaluate the quality of the data and detect possible missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "First Name                   50000\n",
       "Last Name                    50000\n",
       "Email                        50000\n",
       "Application Date             50000\n",
       "Country                      50000\n",
       "YOE                          50000\n",
       "Seniority                    50000\n",
       "Technology                   50000\n",
       "Code Challenge Score         50000\n",
       "Technical Interview Score    50000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete Data: All columns contain exactly 50,000 records, indicating that there are no null values in any of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After reading the csv with the data, we are going to create the database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code fragment is responsible for invoking the create_database() function, located in the src.database.database_create module. The execution of this function allows the creation of a database in the system, ensuring that the necessary infrastructure to store information is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando la base de datos...\n",
      "Base de datos 'candidates' creada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Creating the database...\")\n",
    "    create_database()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implies that the system had the appropriate permissions and that the connection to the database engine went smoothly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the CSV to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = connect_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establishes a connection to the database using SQLAlchemy, an ORM (Object Relational Mapper) widely used in data analysis environments. \n",
    "\n",
    "This function, located in src.database.db_connection, is responsible for establishing the connection to the database engine. a engine variable stores the connection object returned by connect_db().\n",
    "This object will allow the execution of SQL queries and interaction with the database from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos insertados correctamente\n"
     ]
    }
   ],
   "source": [
    "data.to_sql(\"rawCandidates\", engine, if_exists=\"replace\", index=False)\n",
    "print(\"Data inserted correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implemented code follows a structured flow for loading, connecting and inserting data into a SQL database. It has been ensured that the information stored in the CSV file is properly processed and sent to the database, which facilitates its subsequent analysis and exploitation.\n",
    "\n",
    "to_sql() : This Pandas function allows writing a DataFrame to a SQL table.\n",
    "“rawCandidates: It is the name of the table in the database where the data will be stored.\n",
    "engine: It is the database connection object, previously created with connect_db().\n",
    "if_exists=“replace”: If the table already exists, it replaces it completely with the new data.\n",
    "\n",
    "Finally there is the result that indicates that the data were correctly uploaded to the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification that the data has been loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   First Name   Last Name                      Email Application Date  \\\n",
      "0  Bernadette   Langworth        leonard91@yahoo.com       2021-02-26   \n",
      "1      Camryn    Reynolds        zelda56@hotmail.com       2021-09-09   \n",
      "2       Larue      Spinka   okey_schultz41@gmail.com       2020-04-14   \n",
      "3        Arch      Spinka     elvera_kulas@yahoo.com       2020-10-01   \n",
      "4       Larue  Altenwerth  minnie.gislason@gmail.com       2020-05-20   \n",
      "\n",
      "   Country  YOE  Seniority                         Technology  \\\n",
      "0   Norway    2     Intern                      Data Engineer   \n",
      "1   Panama   10     Intern                      Data Engineer   \n",
      "2  Belarus    4  Mid-Level                     Client Success   \n",
      "3  Eritrea   25    Trainee                          QA Manual   \n",
      "4  Myanmar   13  Mid-Level  Social Media Community Management   \n",
      "\n",
      "   Code Challenge Score  Technical Interview Score  \n",
      "0                     3                          3  \n",
      "1                     2                         10  \n",
      "2                    10                          9  \n",
      "3                     7                          1  \n",
      "4                     9                          7  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql_query('SELECT * FROM \"rawCandidates\"', engine)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A connection to the previously configured database is established and the data stored in the rawCandidates table is extracted. This table contains the information that was previously loaded from the CSV file.\n",
    "\n",
    "The main purpose of this operation is to verify the correct insertion of the data, ensuring that the information stored in the database matches the original source. For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Name                   50000\n",
      "Last Name                    50000\n",
      "Email                        50000\n",
      "Application Date             50000\n",
      "Country                      50000\n",
      "YOE                          50000\n",
      "Seniority                    50000\n",
      "Technology                   50000\n",
      "Code Challenge Score         50000\n",
      "Technical Interview Score    50000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained confirm that the data loading was successful and that all columns contain the same number of records, with no missing values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
